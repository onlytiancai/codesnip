use std::cmp::Ordering;
use std::collections::BinaryHeap;
use std::error::Error;
use std::fs::File;
use std::path::{Path, PathBuf};

use clap::Parser;
use csv::{ReaderBuilder, StringRecord, WriterBuilder};
use tempfile::TempDir;

const MAX_OPEN_FILES: usize = 64;

/* ---------- CLI ---------- */

#[derive(Parser, Debug)]
struct Args {
    input: PathBuf,
    output: PathBuf,

    #[arg(long)]
    chunk_size: usize,

    #[arg(long)]
    sort_col: usize,

    /// æ˜¯å¦æŒ‰æ’åºåˆ—å»é‡ï¼ˆåªåœ¨æœ€åä¸€è½®ç”Ÿæ•ˆï¼‰
    #[arg(long, default_value_t = false)]
    dedup: bool,

    /// æŒ‡å®šä¸´æ—¶ç›®å½•ï¼ˆå»ºè®®æ”¾åˆ°å¤§ç£ç›˜ï¼‰
    #[arg(long)]
    temp_dir: Option<PathBuf>,
}

/* ---------- heap item ---------- */

#[derive(Debug)]
struct HeapItem {
    key: String,
    chunk_idx: usize,
    record: StringRecord,
}

impl Eq for HeapItem {}

impl PartialEq for HeapItem {
    fn eq(&self, other: &Self) -> bool {
        self.key == other.key
    }
}

impl Ord for HeapItem {
    fn cmp(&self, other: &Self) -> Ordering {
        // BinaryHeap æ˜¯æœ€å¤§å †ï¼Œåè½¬å®ç°æœ€å°å †
        other.key.cmp(&self.key)
    }
}

impl PartialOrd for HeapItem {
    fn partial_cmp(&self, other: &Self) -> Option<Ordering> {
        Some(self.cmp(other))
    }
}

/* ---------- main ---------- */

fn main() -> Result<(), Box<dyn Error>> {
    let args = Args::parse();

    let tempdir = prepare_temp_dir(args.temp_dir.as_ref())?;
    println!("ä½¿ç”¨ä¸´æ—¶ç›®å½•: {:?}", tempdir.path());

    let mut rdr = ReaderBuilder::new()
        .has_headers(true)
        .from_path(&args.input)?;

    let headers = rdr.headers()?.clone();

    println!("å¼€å§‹åˆ†å—æ’åºâ€¦");

    let mut chunks: Vec<PathBuf> = Vec::new();
    let mut buffer = Vec::with_capacity(args.chunk_size);

    for (i, row) in rdr.records().enumerate() {
        buffer.push(row?);

        if buffer.len() == args.chunk_size {
            let path = tempdir
                .path()
                .join(format!("chunk_{}.csv", chunks.len()));
            write_sorted_chunk(&buffer, &headers, args.sort_col, &path)?;
            chunks.push(path);
            buffer.clear();
            println!("å·²å®Œæˆåˆ†å— {}", chunks.len());
        }

        if (i + 1) % 1_000_000 == 0 {
            println!("å·²è¯»å– {} è¡Œ", i + 1);
        }
    }

    if !buffer.is_empty() {
        let path = tempdir
            .path()
            .join(format!("chunk_{}.csv", chunks.len()));
        write_sorted_chunk(&buffer, &headers, args.sort_col, &path)?;
        chunks.push(path);
        println!("å·²å®Œæˆåˆ†å— {}", chunks.len());
    }

    println!("åˆ†å—å®Œæˆï¼Œå…± {} ä¸ª chunk", chunks.len());

    let final_path = merge_in_rounds(
        chunks,
        &headers,
        args.sort_col,
        args.dedup,
        tempdir.path(),
    )?;

    std::fs::copy(&final_path, &args.output)?;
    println!("æ’åºå®Œæˆï¼Œè¾“å‡ºå†™å…¥ {:?}", args.output);

    Ok(())
}

/* ---------- temp dir ---------- */

fn prepare_temp_dir(dir: Option<&PathBuf>) -> Result<TempDir, Box<dyn Error>> {
    if let Some(p) = dir {
        std::fs::create_dir_all(p)?;
        Ok(TempDir::new_in(p)?)
    } else {
        Ok(TempDir::new()?)
    }
}

/* ---------- write sorted chunk ---------- */

fn write_sorted_chunk(
    records: &[StringRecord],
    headers: &StringRecord,
    sort_col: usize,
    path: &PathBuf,
) -> Result<(), Box<dyn Error>> {
    let mut data = records.to_vec();
    data.sort_by(|a, b| a[sort_col].cmp(&b[sort_col]));

    let file = File::create(path)?;
    let mut wtr = WriterBuilder::new().has_headers(true).from_writer(file);

    wtr.write_record(headers)?;
    for r in data {
        wtr.write_record(&r)?;
    }
    wtr.flush()?;
    Ok(())
}

/* ---------- multi-pass merge ---------- */

fn merge_in_rounds(
    mut chunks: Vec<PathBuf>,
    headers: &StringRecord,
    sort_col: usize,
    final_dedup: bool,
    temp_root: &Path,
) -> Result<PathBuf, Box<dyn Error>> {
    let mut round = 0;

    while chunks.len() > 1 {
        round += 1;
        println!(
            "å¼€å§‹ç¬¬ {} è½®å½’å¹¶ï¼Œchunk æ•° = {}",
            round,
            chunks.len()
        );

        let is_last_round = chunks.len() <= MAX_OPEN_FILES;
        let dedup_this_round = is_last_round && final_dedup;

        let mut next = Vec::new();

        for (i, group) in chunks.chunks(MAX_OPEN_FILES).enumerate() {
            let out = temp_root.join(format!("merge_r{}_{}.csv", round, i));
            merge_group(
                group,
                headers,
                sort_col,
                dedup_this_round,
                &out,
            )?;
            next.push(out);
        }

        // ğŸ‘‡ åˆ é™¤ä¸Šä¸€è½® chunkï¼Œé‡Šæ”¾ç£ç›˜ç©ºé—´
        for old in &chunks {
            let _ = std::fs::remove_file(old);
        }

        chunks = next;
    }

    Ok(chunks.remove(0))
}

/* ---------- merge one group ---------- */

fn merge_group(
    group: &[PathBuf],
    headers: &StringRecord,
    sort_col: usize,
    dedup: bool,
    out_path: &PathBuf,
) -> Result<(), Box<dyn Error>> {
    const PRINT_EVERY: usize = 1_000_000;

    println!(
        "  å¼€å§‹å½’å¹¶ {} ä¸ª chunk -> {:?}",
        group.len(),
        out_path.file_name().unwrap()
    );

    let mut readers = Vec::new();
    for p in group {
        let f = File::open(p)?;
        readers.push(ReaderBuilder::new().has_headers(true).from_reader(f));
    }

    let mut heap = BinaryHeap::<HeapItem>::new();

    for (idx, rdr) in readers.iter_mut().enumerate() {
        if let Some(r) = rdr.records().next() {
            let rec = r?;
            heap.push(HeapItem {
                key: rec[sort_col].to_string(),
                chunk_idx: idx,
                record: rec,
            });
        }
    }

    let out_file = File::create(out_path)?;
    let mut wtr = WriterBuilder::new().has_headers(true).from_writer(out_file);
    wtr.write_record(headers)?;

    let mut last_key: Option<String> = None;
    let mut processed: usize = 0;
    let mut emitted: usize = 0;

    while let Some(item) = heap.pop() {
        processed += 1;

        let emit = if dedup {
            last_key.as_deref() != Some(&item.key)
        } else {
            true
        };

        if emit {
            wtr.write_record(&item.record)?;
            last_key = Some(item.key.clone());
            emitted += 1;
        }

        if processed % PRINT_EVERY == 0 {
            println!(
                "    å·²å¤„ç† {:>10} è¡Œï¼Œè¾“å‡º {:>10} è¡Œ",
                processed, emitted
            );
        }

        let idx = item.chunk_idx;
        if let Some(r) = readers[idx].records().next() {
            let rec = r?;
            heap.push(HeapItem {
                key: rec[sort_col].to_string(),
                chunk_idx: idx,
                record: rec,
            });
        }
    }

    wtr.flush()?;

    println!(
        "  å½’å¹¶å®Œæˆï¼šå¤„ç† {} è¡Œï¼Œè¾“å‡º {} è¡Œ -> {:?}",
        processed,
        emitted,
        out_path.file_name().unwrap()
    );

    Ok(())
}
