# 更新数据

参考链接：https://github.com/microsoft/qlib/tree/main/scripts/data_collector/yahoo

终端里要先设置代理，否则 yahoo 的数据下载不下来

## 1. 下载原始数据，

时间较久，会下载 5000 多只股票从 2005 到最近一天的数据，目标目录是 `~/.qlib/stock_data/source/cn_data`

    cd scripts/data_collector/yahoo
    python collector.py download_data --source_dir ~/.qlib/stock_data/source/cn_data

    ls  ~/.qlib/stock_data/source/cn_data | wc -l
        5186

    head -n2 ~/.qlib/stock_data/source/cn_data/sh000300.csv
    date,open,close,high,low,volume,money,change,adjclose,symbol
    2005-01-04,994.77,982.79,994.77,980.66,7412868.0,4431977400.0,0.0,982.79,sh000300        

## 2. 归一化数据

目标目录是 `~/.qlib/stock_data/source/cn_1d_nor`

    python collector.py normalize_data --source_dir ~/.qlib/stock_data/source/cn_data --normalize_dir ~/.qlib/stock_data/source/cn_1d_nor --region CN --interval 1d

期间可能会报错，主要是因为原始数据里，有的时间格式不正确，本来应该只有年月日，但有的有天，可以增加报错的相关文件里加日志，打印出错的原始文件路径。

一种问题是，如果正在开盘，它可能会拉取今天的数据，这时候最后一条数据，格式是有问题的，用如下脚本删掉每个文件的最后一行，

    cd ~/.qlib/stock_data/source/cn_data
    # 执行前记得备份整个目录
    for f in *.csv; do
        sed -i '' '/2025-09-01/d' "$f"
    done

可能还有一些文件的某些行的日期格式不正确，继续用 sed 清理

    for f in *.csv; do                  
        sed -E -i '' 's/([0-9]{4}-[0-9]{2}-[0-9]{2}) [0-9]{2}:[0-9]{2}:[0-9]{2}\+08:00/\1/g' "$f"
    done

再有问题就是比较少的问题了，手工修复即可

## 转换成 qlib bin 格式

这一步一般没啥错


    python dump_bin.py dump_all --data_path ~/.qlib/stock_data/source/cn_1d_nor --qlib_dir ~/.qlib/qlib_data/cn_data --freq day --exclude_fields date,symbol --file_suffix .csv

## 更新 instruments 文件

默认 instruments 配置在 `~/.qlib/qlib_data/cn_data/instruments` 路径下，也需要更新，否则 dataset 加载数据加载不全，即使原始数据已经全了

    ls ~/.qlib/qlib_data/cn_data/instruments
    all.txt		csi100.txt	csi300.txt	csi500.txt
    head ~/.qlib/qlib_data/cn_data/instruments/csi100.txt
    SH600000	2007-05-29	2020-10-20
    SH600009	2018-06-11	2020-10-20
    SH600015	2007-05-29	2020-10-20
    SH600016	2007-05-29	2020-10-20

进入如下目录，并执行脚本更新 instruments，要单独安装一些 excel 相关的依赖

    cd /Users/huhao/src/qlib/scripts/data_collector/cn_index
    python collector.py --index_name csi300 --qlib_dir ~/.qlib/qlib_data/cn_data --method parse_instruments

## 检查数据

它会检查是否有缺失值，是否有不合常理的离群值，比较大的波动等。

    python scripts/check_data_health.py check_data --qlib_dir ~/.qlib/qlib_data/cn_data

## 数据验证

以下代码可测试能否加载到最新的数据

    import qlib
    from qlib.data import D
    from qlib.contrib.data.handler import Alpha158

    # ---------------------------
    # 1. 初始化，确保 provider_uri 指向正确的路径
    # ---------------------------
    qlib.init(provider_uri="~/.qlib/qlib_data/cn_data", region="cn")  # 👈 改成你实际的数据目录

    stocks = ["SH600519", "SZ000001", "SZ300750"]
    instruments = D.instruments(stocks)
    instruments = D.instruments('csi300') # 如果不更新 instruments，这样用 csi300 加载数据会加载不到最新数据

    # ---------------------------
    # 2. 检查原始行情数据的最后日期
    # ---------------------------
    df_raw = D.features(instruments, ["$close"], freq="day")
    print("原始行情最后日期:", df_raw.index.get_level_values("datetime").max())

    # ---------------------------
    # 3. 检查 Alpha158 handler 的最后日期
    # ---------------------------
    data_handler_config = {
        "start_time": "2008-01-01",
        "end_time": "2025-08-25",      # 尽量写最新
        "fit_start_time": "2008-01-01",
        "fit_end_time": "2025-08-25",
        "instruments": instruments,
    }

    h = Alpha158(**data_handler_config)
    df_label = h.fetch(col_set="label")
    print("Alpha158 Label 最后日期:", df_label.index.get_level_values("datetime").max())

    # ---------------------------
    # 4. 如果需要，也可以检查 feature 的最后日期
    # ---------------------------
    df_feat = h.fetch(col_set="feature")
    print("Alpha158 Feature 最后日期:", df_feat.index.get_level_values("datetime").max())