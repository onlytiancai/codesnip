{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900b8dad-6f54-4842-a668-960a05eb5a17",
   "metadata": {},
   "source": [
    "# å¤§æ¨¡å‹è®­ç»ƒå®éªŒ\n",
    "\n",
    "å®éªŒç›®æ ‡ï¼š\n",
    "\n",
    "åœ¨ Hugging Face ä¸ŠåŠ è½½ä¸€ä¸ª**çœŸå®æ–‡æœ¬åˆ†ç±»æ•°æ®é›†**ï¼ˆSST-2ï¼‰ï¼Œä½¿ç”¨ Hugging Face çš„ **Tokenizer** åšåˆ†è¯ï¼Œè®­ç»ƒä¸€ä¸ªå°æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†ç±»ï¼ˆpositive / negativeï¼‰ã€‚\n",
    "\n",
    "ç›®å½•ï¼š\n",
    "\n",
    "1. ç”¨ PyTorch ä»é›¶è®­ç»ƒ Tiny Transformer æ¨¡å‹\n",
    "2. æ”¹è¿› Tiny Transformer è®­ç»ƒæ•ˆæœ\n",
    "3. åœ¨é¢„è®­ç»ƒæ¨¡å‹ distilbert-base-uncased åŸºç¡€ä¸Šåšå¾®è°ƒ\n",
    "4. æé«˜é¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒé€Ÿåº¦\n",
    "\n",
    "è¿è¡Œç¯å¢ƒï¼š\n",
    "\n",
    "* macOS Apple Silicon (M1â€“M4)\n",
    "* PyTorch â‰¥ 2.2ï¼ˆæ”¯æŒ MPSï¼‰\n",
    "* `transformers`ã€`datasets` æ¥è‡ª Hugging Face\n",
    "\n",
    "å®‰è£…ä¾èµ–ï¼š\n",
    "\n",
    "```bash\n",
    "pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "pip install transformers datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94dd3b87-0a32-438b-bd93-b7c9daaf94c5",
   "metadata": {},
   "source": [
    "# ä¸€ã€ç”¨ PyTorch ä»é›¶è®­ç»ƒ Tiny Transformer æ¨¡å‹\n",
    "\n",
    "è®­ç»ƒä¸€ä¸ª éå¸¸å°çš„ Transformer encoder åšåºåˆ—åˆ†ç±»ï¼ˆsynthetic toyï¼‰ï¼Œå±•ç¤º embeddingã€positional encodingã€TransformerEncoderã€è®­ç»ƒå¾ªç¯ä¸ MPS/CPU äº’æ¢ã€‚æ¨¡å‹å¾ˆå°ï¼Œèƒ½åœ¨ M4/macbook ä¸Šå¿«é€Ÿè·‘å®Œã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454c4658-68e9-4cd8-9bac-a2311f1244ae",
   "metadata": {},
   "source": [
    "### 1. å¯¼å…¥ä¾èµ–ä¸è®¾å®šè®¾å¤‡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "022290bd-2ad9-4106-90d6-f75afdc3e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# é€‰æ‹©è®¾å¤‡\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2696fbba-13ea-47e6-ad1e-db03484659b0",
   "metadata": {},
   "source": [
    "### 2. åŠ è½½çœŸå®æ•°æ®é›†ï¼ˆSST-2ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "409d6e95-1a89-4d4c-a800-962a9af21676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 67349\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 872\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['sentence', 'label', 'idx'],\n",
      "        num_rows: 1821\n",
      "    })\n",
      "})\n",
      "{'sentence': 'hide new secretions from the parental units ', 'label': 0, 'idx': 0}\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½ Stanford Sentiment Treebank (SST-2)\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "print(dataset)\n",
    "print(dataset[\"train\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a793dcd-e5f0-4d18-9c08-83f2d26241fa",
   "metadata": {},
   "source": [
    "### 3. åŠ è½½ Hugging Face åˆ†è¯å™¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ad38f4b-92d7-4a01-b342-626b8519b1a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fde553f98554e2299dffcc4604f3754",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/872 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "max_len = 64\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"sentence\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=max_len\n",
    "    )\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"sentence\", \"idx\"])\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "train_dataset = tokenized_datasets[\"train\"]\n",
    "val_dataset = tokenized_datasets[\"validation\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912b4d22-29da-470b-8802-5530fb9a5586",
   "metadata": {},
   "source": [
    "### 4. å®šä¹‰ Tiny Transformer æ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37306a66-9d83-4568-8bd1-74ad1c01123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyTransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=128, nhead=4, num_layers=2, dim_feedforward=256, num_classes=2, max_len=64):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, max_len, d_model))\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward)\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(d_model//2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None):\n",
    "        x = self.embedding(input_ids) + self.pos_embedding[:, :input_ids.size(1)]\n",
    "        x = x.transpose(0, 1)  # [seq, batch, d_model]\n",
    "        x = self.transformer(x)  # [seq, batch, d_model]\n",
    "        x = x.mean(dim=0)  # pool over sequence\n",
    "        logits = self.fc(x)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06cc324-6573-4624-9cc8-62dc9e84ce30",
   "metadata": {},
   "source": [
    "### 5ï¸âƒ£ æ„å»º DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5396353d-e031-40e9-b10d-314c6bbf9ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a78fda-6c61-40d3-8c7e-a01652596d43",
   "metadata": {},
   "source": [
    "### 5. è®­ç»ƒä¸éªŒè¯å¾ªç¯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0e54f30-97ed-4891-b3f0-27d06afcdc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huhao/.pyenv/versions/3.11.9/envs/qlib/lib/python3.11/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06012196b4464f59aa503a0708eb8375",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5078, Acc: 0.7557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c884f76eb824416b33fbbeead529a6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5271, Acc: 0.7672\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7680dbb28f164f6681196cebb31353fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5921, Acc: 0.7764\n"
     ]
    }
   ],
   "source": [
    "model = TinyTransformerClassifier(vocab_size=len(tokenizer), num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    correct, total, total_loss = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "EPOCHS = 3\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for batch in loop:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "    print(f\"Validation Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f0ae34-7398-486a-9478-d587d44ae327",
   "metadata": {},
   "source": [
    "### 6. æµ‹è¯•æ ·ä¾‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eff8bf4-6fcf-4cd5-a9bb-50bcaf91d475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: This movie was surprisingly good!\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "test_sentence = \"This movie was surprisingly good!\"\n",
    "inputs = tokenizer(test_sentence, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=max_len).to(device)\n",
    "logits = model(inputs[\"input_ids\"])\n",
    "pred = torch.argmax(logits, dim=1).item()\n",
    "print(\"Sentence:\", test_sentence)\n",
    "print(\"Predicted sentiment:\", \"positive\" if pred == 1 else \"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3972f-bd15-43d3-996e-0447582cdfe0",
   "metadata": {},
   "source": [
    "### å®éªŒè¯´æ˜\n",
    "\n",
    "| éƒ¨åˆ†        | å†…å®¹                                                                       |\n",
    "| --------- | ------------------------------------------------------------------------ |\n",
    "| æ•°æ®é›†       | [GLUE SST-2](https://huggingface.co/datasets/glue/viewer/sst2)ï¼ˆç”µå½±è¯„è®ºæƒ…æ„Ÿåˆ†ç±»ï¼‰ |\n",
    "| Tokenizer | `distilbert-base-uncased`ï¼ˆçœŸå® BERT è¯è¡¨ï¼‰                                    |\n",
    "| æ¨¡å‹        | è‡ªå®šä¹‰ Tiny Transformerï¼ˆéé¢„è®­ç»ƒï¼‰                                               |\n",
    "| ä»»åŠ¡        | æ–‡æœ¬ â†’ äºŒåˆ†ç±»ï¼ˆæƒ…æ„Ÿææ€§ï¼‰                                                           |\n",
    "| åŠ é€Ÿ        | è‡ªåŠ¨æ£€æµ‹ MPS (Metal GPU)                                                     |\n",
    "| è®­ç»ƒæ—¶é•¿      | M4 Mac ä¸Šçº¦ 1â€“2 åˆ†é’Ÿå³å¯è·‘å®Œå‡ è½®                                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af13a0d9-9eba-4409-8d75-1772912eb323",
   "metadata": {},
   "source": [
    "# äºŒã€æ”¹è¿› Tiny Transformer è®­ç»ƒæ•ˆæœ\n",
    "\n",
    "### æ”¹è¿›ç›®æ ‡\n",
    "\n",
    "| æ”¹è¿›ç‚¹                                   | ç›®çš„          |\n",
    "| ------------------------------------- | ----------- |\n",
    "| å¢å¤§æ¨¡å‹å®¹é‡ï¼ˆ`d_model=256`, `num_layers=3`ï¼‰ | æå‡è¡¨è¾¾èƒ½åŠ›      |\n",
    "| ä½¿ç”¨ Dropoutï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰                     | æå‡æ³›åŒ–        |\n",
    "| å­¦ä¹ ç‡è¡°å‡è°ƒåº¦å™¨                              | æ›´ç¨³å®šæ”¶æ•›       |\n",
    "| å¢åŠ è®­ç»ƒè½®æ•°è‡³ 8                             | å……åˆ†è®­ç»ƒ        |\n",
    "| è‡ªåŠ¨ä¿å­˜æœ€ä¼˜æ¨¡å‹ï¼ˆéªŒè¯é›†æœ€é«˜ accï¼‰                   | ä¿å­˜æœ€ä½³å‚æ•°      |\n",
    "| å¢åŠ  LayerNorm ç¨³å®šæ€§                      | å‡å°‘æ¢¯åº¦çˆ†ç‚¸/æ”¶æ•›éœ‡è¡ |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5583a7a5-918f-4e55-9cf6-d664b049aa67",
   "metadata": {},
   "source": [
    "### 1. æ¨¡å‹å®šä¹‰éƒ¨åˆ†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ce69cd4-efdc-4147-8510-1aedf297dcd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyTransformerClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model=256, nhead=4, num_layers=3, dim_feedforward=512,\n",
    "                 num_classes=2, max_len=64, dropout=0.2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_embedding = nn.Parameter(torch.zeros(1, max_len, d_model))\n",
    "\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            activation='gelu',\n",
    "            batch_first=True,  # å¯ç›´æ¥ä½¿ç”¨ batch ç»´åœ¨å‰çš„è¾“å…¥\n",
    "            norm_first=True,   # LayerNorm å‰ç½®ç¨³å®šè®­ç»ƒ\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "        self.layernorm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(d_model, d_model // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(d_model // 2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids):\n",
    "        x = self.embedding(input_ids) + self.pos_embedding[:, :input_ids.size(1)]\n",
    "        x = self.dropout(x)\n",
    "        x = self.transformer(x)\n",
    "        x = self.layernorm(x)\n",
    "        x = x.mean(dim=1)  # mean pooling\n",
    "        logits = self.fc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecd729cf-c36d-437a-b69a-6ea439b2ece6",
   "metadata": {},
   "source": [
    "### 2. è®­ç»ƒå¾ªç¯éƒ¨åˆ†ï¼ˆå«è°ƒåº¦å™¨ä¸ä¿å­˜ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fe6eb33-99f3-4732-b857-04730ed55dd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/huhao/.pyenv/versions/3.11.9/envs/qlib/lib/python3.11/site-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1299aae6b63d4fc6bced87834f23619d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss=0.5199  Acc=0.7603\n",
      "âœ… Saved new best model at epoch 1 (acc=0.7603)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e313364a6f534a7db3e7314de9e9129a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss=0.5300  Acc=0.7833\n",
      "âœ… Saved new best model at epoch 2 (acc=0.7833)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49eeb69cdcc74bbfb6f1141dfe37147f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss=0.5716  Acc=0.7844\n",
      "âœ… Saved new best model at epoch 3 (acc=0.7844)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e685f221ae541779d4b6e7f35f8a2c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss=0.5301  Acc=0.8050\n",
      "âœ… Saved new best model at epoch 4 (acc=0.8050)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91459f2aa45b410585700929caf76981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss=0.5682  Acc=0.8073\n",
      "âœ… Saved new best model at epoch 5 (acc=0.8073)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dfd92c52b044ee95bb5b0b0214d5e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Val Loss=0.5956  Acc=0.8062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0475845988c5465fa6f8e80e7efca2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Val Loss=0.6262  Acc=0.8062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957d2241711645118cdef386ed5e408d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/1053 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Val Loss=0.6660  Acc=0.8016\n",
      "Training complete! Best validation accuracy: 0.8073394495412844\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "model = TinyTransformerClassifier(vocab_size=len(tokenizer), num_classes=2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=0.01)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
    "\n",
    "best_val_acc = 0.0\n",
    "EPOCHS = 8\n",
    "\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            labels = batch[\"label\"].to(device)\n",
    "            outputs = model(input_ids)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * input_ids.size(0)\n",
    "            preds = outputs.argmax(1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch}\")\n",
    "    running_loss = 0.0\n",
    "    for batch in loop:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        labels = batch[\"label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # é˜²æ­¢æ¢¯åº¦çˆ†ç‚¸\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    scheduler.step()\n",
    "    val_loss, val_acc = evaluate(model, val_loader)\n",
    "    print(f\"Epoch {epoch}: Val Loss={val_loss:.4f}  Acc={val_acc:.4f}\")\n",
    "\n",
    "    # è‡ªåŠ¨ä¿å­˜æœ€ä¼˜æ¨¡å‹\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save(model.state_dict(), \"best_tiny_transformer.pt\")\n",
    "        print(f\"âœ… Saved new best model at epoch {epoch} (acc={val_acc:.4f})\")\n",
    "\n",
    "print(\"Training complete! Best validation accuracy:\", best_val_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaac6eeb-ca22-4f05-852a-3eae35426e3e",
   "metadata": {},
   "source": [
    "### 3. åŠ è½½æ¨¡å‹è¿›è¡Œæµ‹è¯•é¢„æµ‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a09ff484-ee95-4008-96e0-5585eb9d91ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: I really loved this movie, it was brilliant!\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "# åŠ è½½æœ€ä¼˜æ¨¡å‹\n",
    "model2 = TinyTransformerClassifier(vocab_size=len(tokenizer), num_classes=2).to(device)\n",
    "model2.load_state_dict(torch.load(\"best_tiny_transformer.pt\", map_location=device))\n",
    "model2.eval()\n",
    "\n",
    "# æµ‹è¯•ä¸€å¥è¯\n",
    "sentence = \"I really loved this movie, it was brilliant!\"\n",
    "inputs = tokenizer(sentence, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=64)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "logits = model2(inputs[\"input_ids\"])\n",
    "pred = torch.argmax(logits, dim=1).item()\n",
    "print(f\"Sentence: {sentence}\")\n",
    "print(\"Predicted sentiment:\", \"positive\" if pred == 1 else \"negative\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8bfedc-4607-4f8a-a7a9-9fbf511f80a5",
   "metadata": {},
   "source": [
    "# ä¸‰ã€åœ¨é¢„è®­ç»ƒæ¨¡å‹ distilbert-base-uncased åŸºç¡€ä¸Šåšå¾®è°ƒ\n",
    "\n",
    "ç›´æ¥ç”¨ Hugging Face ä¸Šçš„ **é¢„è®­ç»ƒ BERT/DistilBERT** æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚\n",
    "\n",
    "### 1. ä¸ºä»€ä¹ˆä½¿ç”¨é¢„è®­ç»ƒæ¨¡å‹ï¼ˆBERT / DistilBERTï¼‰ï¼Ÿ\n",
    "\n",
    "è¿™æ˜¯ **æ•ˆæœ vs é€Ÿåº¦** çš„æ ¸å¿ƒæƒè¡¡ã€‚å®ƒä»¬æ˜¯â€œé€šç”¨è¯­è¨€çŸ¥è¯†åº“â€\n",
    "\n",
    "* BERT / DistilBERT ä¸æ˜¯éšæœºåˆå§‹åŒ–çš„ç½‘ç»œï¼Œè€Œæ˜¯åœ¨**è¶…å¤§è¯­æ–™**ï¼ˆWikipediaã€BooksCorpus ç­‰ï¼‰ä¸Šé¢„è®­ç»ƒè¿‡çš„ã€‚\n",
    "* å®ƒä»¬å·²ç»**å­¦ä¹ äº†è‹±è¯­è¯­æ³•ã€è¯ä¹‰ã€ä¸Šä¸‹æ–‡å…³ç³»**ã€‚\n",
    "* å› æ­¤ï¼Œåªéœ€è¦**å¾®è°ƒï¼ˆfine-tuneï¼‰å‡ è½®**ï¼Œå°±èƒ½åœ¨æƒ…æ„Ÿåˆ†æã€é—®ç­”ã€åˆ†ç±»ç­‰ä»»åŠ¡ä¸Šå–å¾—éå¸¸é«˜çš„å‡†ç¡®ç‡ã€‚\n",
    "\n",
    "> ä¸¾ä¾‹ï¼š\n",
    ">\n",
    "> * ä½ çš„ Tiny Transformerï¼ˆä»é›¶è®­ç»ƒï¼‰é éšæœºåˆå§‹åŒ–ï¼Œéœ€è¦å­¦ä¹ â€œgoodâ€=æ­£é¢ã€â€œbadâ€=è´Ÿé¢ç­‰å…¨éƒ¨çŸ¥è¯†ã€‚\n",
    "> * BERT å·²ç»â€œçŸ¥é“â€è¿™äº›è¯ä¹‰ï¼Œåªè¦è½»å¾®è°ƒæ•´æœ€åå‡ å±‚å‚æ•°ã€‚\n",
    "\n",
    "ğŸ’¡ æ‰€ä»¥æˆ‘ä»¬é€‰æ‹© BERT / DistilBERTï¼Œæ˜¯å› ä¸ºï¼š\n",
    "\n",
    "* å®ƒä»¬åœ¨å¤§é‡è¯­æ–™ä¸Šé¢„è®­ç»ƒï¼›\n",
    "* å¾®è°ƒæ—¶æ•ˆæœæå¥½ï¼›\n",
    "* Hugging Face æä¾›äº†ç°æˆçš„æƒé‡å’Œåˆ†è¯å™¨ï¼›\n",
    "* å¯¹å¤šæ•° NLP ä»»åŠ¡éƒ½æ˜¯æ ‡å‡† baselineã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d43e4a7-1401-4ea2-a60a-d9c7ede08692",
   "metadata": {},
   "source": [
    "ç¦ç”¨åˆ†è¯å™¨çš„å¹¶å‘åŠŸèƒ½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c559434-8247-43b3-9b99-b797d39af90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c526ccbc-25e5-4aa9-95fa-0f6f4375a743",
   "metadata": {},
   "source": [
    "### 2. å®šä¹‰åˆ†è¯å™¨ï¼Œè®­ç»ƒå‚æ•°ï¼Œè®­ç»ƒå™¨ï¼Œå¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472634a5-fc0e-4686-8dfc-ea8670874b2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 00:35, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.361624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28/28 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.36162370443344116,\n",
       " 'eval_runtime': 2.2198,\n",
       " 'eval_samples_per_second': 392.834,\n",
       " 'eval_steps_per_second': 12.614,\n",
       " 'epoch': 0.047505938242280284}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "dataset = load_dataset(\"glue\", \"sst2\")\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"sentence\"], truncation=True, padding=\"max_length\", max_length=64)\n",
    "\n",
    "tokenized = dataset.map(preprocess, batched=True)\n",
    "tokenized = tokenized.rename_column(\"label\", \"labels\")\n",
    "tokenized.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n",
    "\n",
    "model3 = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    max_steps=200,             # è®­ç»ƒå¤ªæ…¢ï¼Œæˆ‘ä»¬è®­ç»ƒ 200 ä¸ª step å°±åœæ­¢\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model3,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa15105-6e22-4a54-aea6-7d7f0347e660",
   "metadata": {},
   "source": [
    "è®­ç»ƒå¤ªæ…¢ï¼Œæˆ‘ä»¬æå‰åœæ­¢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119d69a8-b528-448a-b74f-aa210841cca6",
   "metadata": {},
   "source": [
    "# å››ã€æé«˜é¢„è®­ç»ƒæ¨¡å‹çš„å¾®è°ƒé€Ÿåº¦\n",
    "\n",
    "### 1. ä¸ºä»€ä¹ˆè®­ç»ƒä¼šå˜æ…¢ï¼Ÿ\n",
    "\n",
    "1. æ¨¡å‹å‚æ•°é‡å·¨å¤§\n",
    "\n",
    "| æ¨¡å‹                     | å‚æ•°é‡     | è¯´æ˜                               |\n",
    "| ---------------------- | ------- | -------------------------------- |\n",
    "| Tiny Transformerï¼ˆä½ è‡ªå†™çš„ï¼‰ | çº¦ 1â€“3 M | å°å‹ç½‘ç»œï¼Œå‡ æ¯«ç§’æ¯ batch                  |\n",
    "| DistilBERT             | ~66 M   | å·²ç»æ˜¯è½»é‡ç‰ˆ                           |\n",
    "| BERT base              | ~110 M  | 12 å±‚ Transformerã€768 hidden size |\n",
    "| RoBERTa / GPT          | æ•°äº¿ä»¥ä¸Š    | ç ”ç©¶çº§æ¨¡å‹                            |\n",
    "\n",
    "â†’ è¿™å°±æ„å‘³ç€æ¯æ¬¡å‰å‘ / åå‘ä¼ æ’­çš„çŸ©é˜µä¹˜æ³•å¼€é”€è¿œè¿œå¤§äºä½ çš„å°æ¨¡å‹ã€‚\n",
    "\n",
    "2ã€‚ é¢„è®­ç»ƒæ¨¡å‹çš„è®¡ç®—å›¾æ›´å¤æ‚\n",
    "\n",
    "* å®ƒåŒ…å« **å¤šå¤´æ³¨æ„åŠ›ã€å±‚å½’ä¸€åŒ–ã€æ®‹å·®è¿æ¥ã€dropout** ç­‰ç»“æ„ï¼›\n",
    "* åŒæ—¶è¿˜è¦è®¡ç®— attention maskï¼›\n",
    "* è€Œä½ çš„å°æ¨¡å‹æ˜¯ç®€åŒ–ç‰ˆï¼ˆæ— å¤æ‚ mask æ“ä½œï¼‰ï¼Œæ˜¾ç„¶å¿«å¾ˆå¤šã€‚\n",
    "\n",
    "3. macOS ä¸Š GPU (MPS) å°šæœªå®Œå…¨ä¼˜åŒ– Transformer\n",
    "\n",
    "* MPSï¼ˆMetal Performance Shadersï¼‰æ¯” CUDA æ…¢çº¦ 2â€“4 å€ï¼ˆå°¤å…¶åœ¨å¤šå¤´æ³¨æ„åŠ›ä¸Šï¼‰ï¼›\n",
    "* BERT å¾®è°ƒåœ¨ macOS ä¸Šé€šå¸¸æ¯”åœ¨ CUDA ä¸Šæ…¢å‡ å€ï¼›\n",
    "* å¯¹ M4 èŠ¯ç‰‡æ¥è¯´ï¼Œè™½ç„¶èŠ¯ç‰‡æ€§èƒ½å¼ºï¼Œä½† PyTorch MPS åç«¯è¿˜æœªè¾¾åˆ° CUDA çš„æˆç†Ÿåº¦ï¼›\n",
    "* è‹¥ä½ çš„ batch size è¾ƒå¤§ï¼ˆä¾‹å¦‚ 32ï¼‰ï¼Œæ˜¾å­˜/å†…å­˜æ‹·è´ä¹Ÿä¼šæˆä¸ºç“¶é¢ˆã€‚\n",
    "\n",
    "ğŸ‘‰ ç®€è¨€ä¹‹ï¼š**æ…¢çš„æ ¹æœ¬åŸå› æ˜¯æ¨¡å‹å¤§ + MPS æ€§èƒ½é™åˆ¶ã€‚**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c409e8bb-5dc7-4be6-bab7-a33295f85a53",
   "metadata": {},
   "source": [
    "### 2. è§£å†³æ€è·¯ï¼šå¦‚ä½•åŠ å¿«è®­ç»ƒï¼Ÿ\n",
    "\n",
    "| æ–¹æ³•                                       | è¯´æ˜                   | å»ºè®®                                                   |\n",
    "| ---------------------------------------- | -------------------- | ---------------------------------------------------- |\n",
    "| âœ… **ç”¨ DistilBERT æ›¿ä»£ BERT**               | å·²æ˜¯è½»é‡åŒ–ç‰ˆæœ¬ï¼Œå‚æ•°å‡åŠ         | æ¨èä½¿ç”¨ `\"distilbert-base-uncased\"`ï¼ˆä½ å·²ç»åœ¨ç”¨ï¼‰              |\n",
    "| âš™ï¸ **é™ä½ max_length**                     | å‡å°‘åºåˆ—é•¿åº¦ï¼ˆ64â†’32ï¼‰å‡å°‘è®¡ç®—é‡   | `tokenizer(..., max_length=32)`                      |\n",
    "| ğŸ”¢ **å‡å°‘ batch_size**                     | å‡å°‘æ˜¾å­˜å‹åŠ›ï¼Œæå‡æ¯æ­¥é€Ÿåº¦        | `batch_size=8` æˆ– `16`                                |\n",
    "| â³ **å†»ç»“åº•å±‚å‚æ•°**                             | å¾®è°ƒæ—¶åªè®­ç»ƒé¡¶éƒ¨åˆ†ç±»å±‚          | è§ä¸‹ä»£ç ç¤ºä¾‹                                               |\n",
    "| ğŸ’¾ **æ··åˆç²¾åº¦è®­ç»ƒ (fp16)**                     | åœ¨ CUDA å¯ç”¨ï¼ŒMPS æš‚ä¸å®Œå…¨æ”¯æŒ | æš‚æ—¶ä¸æ¨è MPS ä¸Šç”¨                                         |\n",
    "| ğŸ§© **DistilBERT Tiny / ALBERT / MiniLM** | æ›´å°æ¨¡å‹ï¼Œå¿« 3â€“5 å€         | `\"prajjwal1/bert-tiny\"`, `\"distilbert-base-uncased\"` |\n",
    "\n",
    "---\n",
    "\n",
    "ç¤ºä¾‹ï¼šåªå¾®è°ƒåˆ†ç±»å¤´ï¼ˆå†»ç»“åº•å±‚å±‚ï¼‰\n",
    "\n",
    "ä½ å¯ä»¥è®© BERT çš„å¤§éƒ¨åˆ†å±‚å†»ç»“ï¼Œåªè®­ç»ƒæœ€åå‡ å±‚ï¼Œè¿™æ ·å¿«å¾ˆå¤šï¼Œç„¶åå†ç”¨ `Trainer` è®­ç»ƒï¼Œé€Ÿåº¦é€šå¸¸ä¼šæå‡ 5â€“10 å€ï¼Œæ•ˆæœç•¥ä½ï¼ˆå‡†ç¡®ç‡ä»å¯ >85%ï¼‰ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e00c64-fdce-487e-ba98-3da29fb96f4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters: 66955010/66955010 (100.00%)\n",
      "Trainable parameters: 592130/66955010 (0.88%)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model4 = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased', max_length=32)\n",
    "\n",
    "def print_trainable_parameters(model):\n",
    "    trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    print(f\"Trainable parameters: {trainable}/{total} ({trainable/total:.2%})\")\n",
    "\n",
    "print_trainable_parameters(model4)\n",
    "\n",
    "# å†»ç»“é™¤æœ€åä¸€å±‚ä»¥å¤–çš„å‚æ•°\n",
    "for name, param in model4.named_parameters():\n",
    "    if \"classifier\" not in name:   # åªè®­ç»ƒåˆ†ç±»å±‚\n",
    "        param.requires_grad = False\n",
    "\n",
    "print_trainable_parameters(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcf4b7b-0dad-4e33-8a96-3929e32dbf5b",
   "metadata": {},
   "source": [
    "### 3. å¼€å§‹å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f374b1df-cd6c-4ad1-bc4f-a4666633b741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25257' max='25257' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25257/25257 11:46, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.366200</td>\n",
       "      <td>0.390276</td>\n",
       "      <td>0.826835</td>\n",
       "      <td>0.824214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373500</td>\n",
       "      <td>0.388247</td>\n",
       "      <td>0.832569</td>\n",
       "      <td>0.833713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.385876</td>\n",
       "      <td>0.832569</td>\n",
       "      <td>0.834842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='218' max='109' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [109/109 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3858757019042969,\n",
       " 'eval_accuracy': 0.8325688073394495,\n",
       " 'eval_f1': 0.834841628959276,\n",
       " 'eval_runtime': 2.7555,\n",
       " 'eval_samples_per_second': 316.459,\n",
       " 'eval_steps_per_second': 39.557,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    dataloader_pin_memory=False,\n",
    ")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, predictions)\n",
    "    f1 = f1_score(labels, predictions)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model4,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized[\"train\"],\n",
    "    eval_dataset=tokenized[\"validation\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61f1fc5d-2d17-4d05-9634-4a08ba1320e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3858757019042969, 'eval_accuracy': 0.8325688073394495, 'eval_f1': 0.834841628959276, 'eval_runtime': 2.6871, 'eval_samples_per_second': 324.508, 'eval_steps_per_second': 40.563, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfb9269-2536-4813-bf1d-f7cb468cd49e",
   "metadata": {},
   "source": [
    "### 4. æµ‹è¯•å¾®è°ƒæ•ˆæœ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd115a1b-c3f2-45b6-a273-d961376ee001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This movie was absolutely wonderful!\n",
      " â†’ Predicted sentiment: positive\n",
      "\n",
      "The plot was terrible and the acting was worse.\n",
      " â†’ Predicted sentiment: negative\n",
      "\n",
      "It's okay, not great but not bad either.\n",
      " â†’ Predicted sentiment: positive\n",
      "\n"
     ]
    }
   ],
   "source": [
    "texts = [\n",
    "    \"This movie was absolutely wonderful!\",\n",
    "    \"The plot was terrible and the acting was worse.\",\n",
    "    \"It's okay, not great but not bad either.\"\n",
    "]\n",
    "\n",
    "model4.to(\"mps\")\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, max_length=64, return_tensors=\"pt\").to(\"mps\")\n",
    "model4.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model4(**inputs)\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "\n",
    "for text, pred in zip(texts, predictions):\n",
    "    label = \"positive\" if pred.item() == 1 else \"negative\"\n",
    "    print(f\"{text}\\n â†’ Predicted sentiment: {label}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4a9030-9dfd-49ef-b944-4ee285a1a04c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
