# wawa_transformer.py

模型说明：

1. **核心组件**：包含位置编码、多头注意力、前馈神经网络等Transformer关键模块
2. **结构划分**：分为编码器层（自注意力+前馈）和解码器层（掩蔽自注意力+交叉注意力+前馈）
3. **参数说明**：
   - `d_model`：模型隐藏层维度（默认512）
   - `num_layers`：编码器/解码器堆叠层数（默认6）
   - `num_heads`：注意力头数（默认8）
   - `d_ff`：前馈网络中间层维度（默认2048）

实际使用时，需根据任务（如翻译、文本生成）调整掩码策略，并添加适当的训练流程（损失函数、优化器等）。

# test.py

一个简单的**文本翻译任务用例**来测试Transformer模型，模拟从"简单数字序列"到"字母序列"的翻译（便于直观验证）。


### 任务设定
- **输入（源序列）**：数字序列（如 `[1, 2, 3]`）
- **输出（目标序列）**：对应字母序列（如 `[A, B, C]`，其中1→A，2→B，…，5→E）
- **词汇表**：
  - 源词汇表：`{0: <PAD>, 1:1, 2:2, 3:3, 4:4, 5:5}`（0为填充符）
  - 目标词汇表：`{0: <PAD>, 1:A, 2:B, 3:C, 4:D, 5:E, 6:<SOS>, 7:<EOS>}`（6为起始符，7为结束符）



### 用例说明
1. **任务简化**：用数字→字母的简单映射验证模型是否能学习序列转换，避免复杂文本预处理
2. **模型轻量化**：减小 `d_model`、`num_layers` 等参数，加快训练速度
3. **核心验证点**：
   - 能否通过自注意力捕捉输入序列的依赖关系
   - 能否通过交叉注意力关联源序列和目标序列
   - 解码器是否会生成符合规则的输出（含起始符和结束符）

如果输出不符合预期，可增加训练轮次（如200轮）或调整模型参数（如增大 `d_model`）。

输出
```
$ python test.py
开始训练，总训练样本数: 28
Epoch 20/300, Loss: 0.3004
Epoch 40/300, Loss: 0.0045
Epoch 60/300, Loss: 0.3947
Epoch 80/300, Loss: 0.0629
Epoch 100/300, Loss: 0.7253
Epoch 120/300, Loss: 0.1047
Epoch 140/300, Loss: 0.0028
Epoch 160/300, Loss: 0.0482
Epoch 180/300, Loss: 0.0843
Epoch 200/300, Loss: 0.0038
Epoch 220/300, Loss: 0.1479
Epoch 240/300, Loss: 0.2682
Epoch 260/300, Loss: 0.0026
Epoch 280/300, Loss: 0.2107
Epoch 300/300, Loss: 0.0448

测试用例 1:
输入（数字）：[3, 4]
模型输出（字母）：['< SOS >', 'C', 'D', '<EOS>']
预期输出：['< SOS >', 'C', 'D', '<EOS>']
是否正确：✓

测试用例 2:
输入（数字）：[1, 2]
模型输出（字母）：['< SOS >', 'A', 'B', '<EOS>']
预期输出：['< SOS >', 'A', 'B', '<EOS>']
是否正确：✓

测试用例 3:
输入（数字）：[5]
模型输出（字母）：['< SOS >', 'E', '<EOS>']
预期输出：['< SOS >', 'E', '<EOS>']
是否正确：✓

测试用例 4:
输入（数字）：[2, 3, 4]
模型输出（字母）：['< SOS >', 'B', 'C', 'D', '<EOS>']
预期输出：['< SOS >', 'B', 'C', 'D', '<EOS>']
是否正确：✓
```
## QA

