{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca05a754-59e1-4217-ba5d-1229243802c5",
   "metadata": {},
   "source": [
    "## 问题 1\n",
    "\n",
    "> 介绍peft的LoraConfig 和用于应用 p-tuning 的 PromptEncoderConfig，各用于什么场景"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e0163f-57ea-4aec-b6f2-6972e9b2a0fb",
   "metadata": {},
   "source": [
    "非常好的问题！我们来详细讲讲 **PEFT（Parameter-Efficient Fine-Tuning）** 中两个核心配置类：\n",
    "👉 `LoraConfig` 和 👉 `PromptEncoderConfig`。\n",
    "\n",
    "这两个类代表两种**不同的参数高效微调策略**，分别适用于不同的模型和任务场景。\n",
    "\n",
    "---\n",
    "\n",
    "## 一、`LoraConfig` —— LoRA（Low-Rank Adaptation）\n",
    "\n",
    "### 🌟 核心思想\n",
    "\n",
    "LoRA 的核心是：\n",
    "**在冻结原模型参数的情况下，只为特定层（如 Attention 的权重矩阵）添加低秩可训练矩阵。**\n",
    "\n",
    "原始权重矩阵 `W`（维度 d×k）在训练中不更新，而是增加两个小矩阵：\n",
    "\n",
    "> ( W' = W + BA )，其中 A ∈ ℝ^{r×k}, B ∈ ℝ^{d×r}，r ≪ d, k\n",
    "\n",
    "这使得训练参数量大大减少。\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ `LoraConfig` 主要参数\n",
    "\n",
    "| 参数               | 含义                         | 示例                                       |\n",
    "| ---------------- | -------------------------- | ---------------------------------------- |\n",
    "| `r`              | 低秩矩阵的秩（rank），控制可训练参数规模     | 通常 4、8、16                                |\n",
    "| `lora_alpha`     | 缩放因子，控制 LoRA 的更新强度         | 通常 16 或 32                               |\n",
    "| `target_modules` | 需要插入 LoRA 的层名              | 如 `[\"q_proj\", \"v_proj\"]`（适用于Transformer） |\n",
    "| `lora_dropout`   | 在 LoRA 层前使用 dropout（防止过拟合） | 0.05                                     |\n",
    "| `bias`           | 是否训练 bias                  | `\"none\"` 或 `\"all\"`                       |\n",
    "| `task_type`      | 指定任务类型（用于 PEFT 框架自动注册）     | `\"CAUSAL_LM\"`, `\"SEQ_CLS\"`, 等            |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 适用场景\n",
    "\n",
    "* 大型 Transformer 模型（BERT、GPT、LLaMA、T5、Falcon 等）\n",
    "* 任务：文本生成、问答、分类、指令微调等\n",
    "* 资源有限场景下的高效微调\n",
    "\n",
    "📍 **典型用途：**\n",
    "对 **大语言模型（LLM）** 进行下游任务指令微调（Instruction Tuning），而不破坏原模型性能。\n",
    "\n",
    "---\n",
    "\n",
    "## 二、`PromptEncoderConfig` —— P-Tuning v2 / Prompt Tuning\n",
    "\n",
    "### 🌟 核心思想\n",
    "\n",
    "P-Tuning v2 通过在模型输入中添加**可训练的虚拟提示向量（prompt embeddings）**，让模型学习如何根据任务调整上下文表示。\n",
    "不同于 LoRA 改动权重，Prompt Tuning 只在输入侧加入参数。\n",
    "\n",
    "Prompt 向量通常通过一个小型 **Prompt Encoder（如 LSTM 或 MLP）** 生成。\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ `PromptEncoderConfig` 主要参数\n",
    "\n",
    "| 参数                    | 含义                           | 示例                            |\n",
    "| --------------------- | ---------------------------- | ----------------------------- |\n",
    "| `num_virtual_tokens`  | 虚拟 prompt token 数量           | 20, 50, 100                   |\n",
    "| `encoder_hidden_size` | Prompt 编码器隐藏层维度              | 128, 256                      |\n",
    "| `token_dim`           | 词向量维度（一般与模型 embedding 大小一致）  | 自动检测                          |\n",
    "| `encoder_type`        | Prompt 编码器类型（`mlp` 或 `lstm`） | `\"mlp\"`                       |\n",
    "| `task_type`           | 指定任务类型（用于 PEFT 框架）           | `\"CAUSAL_LM\"`, `\"SEQ_CLS\"`, 等 |\n",
    "\n",
    "---\n",
    "\n",
    "### 🧠 适用场景\n",
    "\n",
    "* 模型输入端可插入 Prompt embedding 的任务（尤其适合 encoder-decoder 或 decoder-only 模型）\n",
    "* 低资源任务（例如只有几百条样本）\n",
    "* 不想修改模型结构或参数的情况\n",
    "\n",
    "📍 **典型用途：**\n",
    "\n",
    "* 分类任务（如情感分析）\n",
    "* 少样本学习（few-shot）\n",
    "* 文本生成任务中加入任务提示（prompt-based fine-tuning）\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 对比总结\n",
    "\n",
    "| 对比项        | LoRA (`LoraConfig`) | P-Tuning / Prompt Tuning (`PromptEncoderConfig`) |\n",
    "| ---------- | ------------------- | ------------------------------------------------ |\n",
    "| 参数插入位置     | 模型权重层（如 attention）  | 输入嵌入层（embedding）                                 |\n",
    "| 是否修改模型结构   | 是（增加 LoRA 层）        | 否（仅加虚拟 token）                                    |\n",
    "| 训练参数量      | 少（低秩矩阵）             | 极少（几十个虚拟 token）                                  |\n",
    "| 是否需要模型内部访问 | 是（要知道目标层）           | 否（只要 embedding 层即可）                              |\n",
    "| 典型任务       | 指令微调、大模型适配          | 少样本分类、小样本生成                                      |\n",
    "| 优点         | 兼容性好，效果稳定           | 更轻量，训练更快                                         |\n",
    "| 缺点         | 需要知道模型内部结构          | 效果可能不如 LoRA 稳定                                   |\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 小结\n",
    "\n",
    "* **`LoraConfig`**：适合大模型下游任务微调，**修改权重层结构（中层适配）**。\n",
    "* **`PromptEncoderConfig`**：适合轻量任务或低资源场景，**只在输入端学习任务提示（前层适配）**。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ca1b3e-36a3-40fc-88f7-73f01283300a",
   "metadata": {},
   "source": [
    "# 问题 2\n",
    "\n",
    "因果语言模型训练\n",
    "\n",
    "https://huggingface.co/docs/transformers/tasks/language_modeling\n",
    "\n",
    "There are two types of language modeling, causal and masked. This guide illustrates causal language modeling. Causal language models are frequently used for text generation. You can use these models for creative applications like choosing your own text adventure or an intelligent coding assistant like Copilot or CodeParrot.\n",
    "\n",
    "语言建模分为因果型和掩码型两种。本指南将重点介绍因果型语言建模。因果型语言模型常用于文本生成。您可以将这些模型用于各种创意应用，例如互动式文本冒险游戏或像 Copilot 或 CodeParrot 这样的智能编程助手。\n",
    "\n",
    "notebook list\n",
    "\n",
    "https://huggingface.co/spaces/PEFT/causal-language-modeling"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
